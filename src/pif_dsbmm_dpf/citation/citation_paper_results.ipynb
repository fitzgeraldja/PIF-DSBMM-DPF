{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error as mse_f\n",
    "from scipy import sparse\n",
    "from scipy.stats import gamma\n",
    "from scipy.stats import ttest_ind\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_model_names = models = {\n",
    "    \"dsbmm_dpf.z-only\": \"Ours-no-meta\",\n",
    "    \"dsbmm_dpf.z-theta-joint\": \"Ours\",\n",
    "    # 'spf.main':'MSPF',\n",
    "    \"unadjusted.main\": \"Unadjusted\",\n",
    "    \"network_pref_only.main\": \"Net.-only\",\n",
    "    \"topic_only.main\": \"Topic-only\",\n",
    "    \"no_unobs.main\": \"Oracle\",\n",
    "    \"topic_only_oracle.main\": \"Topic-oracle\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_kv = tuple(paper_model_names.items())\n",
    "for k, v in tmp_kv:\n",
    "    if \"dsbmm_dpf\" in k:\n",
    "        paper_model_names[k + \"-ndc\"] = v + \"-NDC\"\n",
    "\n",
    "tmp_dict = {\n",
    "    k + \"old_subs\" + \"_ewcnone\" + \"_rcolmain_adm1_1hot\": v + \"-old-A\"\n",
    "    for k, v in paper_model_names.items()\n",
    "    if \"dsbmm_dpf\" not in k\n",
    "}\n",
    "tmp_dict.update(\n",
    "    {\n",
    "        k + \"pres_subs\" + \"_ewcnone\" + \"_rcolmain_adm1_1hot\": v + \"-pres-A\"\n",
    "        for k, v in paper_model_names.items()\n",
    "        if \"dsbmm_dpf\" not in k\n",
    "    }\n",
    ")\n",
    "sub_choice_pretty = {\"old_subs\": \"-old\", \"pres_subs\": \"-pres\"}\n",
    "reg_choice_pretty = {\"adm1\": \"-A\", \"ctry\": \"-C\"}\n",
    "for k, v in paper_model_names.items():\n",
    "    if \"dsbmm_dpf\" in k:\n",
    "        for sub_choice in [\"old_subs\", \"pres_subs\"]:\n",
    "            for region in [\"adm1\", \"ctry\"]:\n",
    "                tmp_dict[k + f\"{sub_choice}_ewcnone_rcolmain_{region}_1hot\"] = (\n",
    "                    v + sub_choice_pretty[sub_choice] + reg_choice_pretty[region]\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_paper_model_names = tmp_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(exp_results, regimes, models, exps=10, print_notfound=False):\n",
    "    ncols = len(regimes.keys())\n",
    "    nrows = len(models)\n",
    "    results = np.zeros((nrows, ncols))\n",
    "    std = np.zeros((nrows, ncols))\n",
    "    alt_results = np.zeros((nrows, ncols))\n",
    "    alt_std = np.zeros((nrows, ncols))\n",
    "\n",
    "    col_idx = 0\n",
    "    for regime, c in regimes.items():\n",
    "        row_idx = 0\n",
    "        for model in models:\n",
    "            mse = np.zeros((exps, 4))\n",
    "            for i in range(exps):\n",
    "                try:\n",
    "                    beta_predicted = exp_results[c][model][i][0]\n",
    "                    truth = exp_results[c][model][i][1]\n",
    "                    sq_err = (beta_predicted - truth) ** 2\n",
    "                    mse[i] = sq_err.mean(axis=0)\n",
    "                except:\n",
    "                    if print_notfound:\n",
    "                        print(model, \"exp\", i, \"not found\")\n",
    "            results[row_idx][col_idx] = round(mse.mean() * 1000, 2)\n",
    "            std[row_idx][col_idx] = round(mse.std() * 1000, 2)\n",
    "\n",
    "            alt_results[row_idx][col_idx] = round(mse[:, :-1].mean() * 1000, 2)\n",
    "            alt_std[row_idx][col_idx] = round(mse[:, :-1].std() * 1000, 2)\n",
    "\n",
    "            row_idx += 1\n",
    "        col_idx += 1\n",
    "\n",
    "    proper_names = [full_paper_model_names[m] for m in models]\n",
    "    col_names = list(regimes.keys())\n",
    "    df = pd.DataFrame(results, index=proper_names, columns=col_names, dtype=str)\n",
    "    std_df = pd.DataFrame(std, index=proper_names, columns=col_names, dtype=str)\n",
    "    df = df + \"$\\pm$\" + std_df\n",
    "\n",
    "    alt_df = pd.DataFrame(alt_results, index=proper_names, columns=col_names, dtype=str)\n",
    "    alt_std_df = pd.DataFrame(alt_std, index=proper_names, columns=col_names, dtype=str)\n",
    "    alt_df = alt_df + \"$\\pm$\" + alt_std_df\n",
    "    return df, alt_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsbmm_dpf.z-onlyold_subs_ewcnone_rcolmain_adm1_1hot found\n",
      "dsbmm_dpf.z-onlypres_subs_ewcnone_rcolmain_adm1_1hot found\n",
      "dsbmm_dpf.z-theta-jointold_subs_ewcnone_rcolmain_adm1_1hot found\n",
      "dsbmm_dpf.z-theta-jointold_subs_ewcnone_rcolmain_ctry_1hot found\n",
      "dsbmm_dpf.z-theta-jointpres_subs_ewcnone_rcolmain_adm1_1hot found\n",
      "dsbmm_dpf.z-theta-jointpres_subs_ewcnone_rcolmain_ctry_1hot found\n",
      "dsbmm_dpf.z-theta-joint-ndcold_subs_ewcnone_rcolmain_adm1_1hot found\n",
      "dsbmm_dpf.z-theta-joint-ndcpres_subs_ewcnone_rcolmain_adm1_1hot found\n",
      "dsbmm_dpf.z-onlyold_subs_ewcnone_rcolmain_ctry_1hot found\n",
      "dsbmm_dpf.z-onlypres_subs_ewcnone_rcolmain_ctry_1hot found\n",
      "unadjusted.mainold_subs_ewcnone_rcolmain_adm1_1hot found\n",
      "unadjusted.mainpres_subs_ewcnone_rcolmain_adm1_1hot found\n",
      "network_pref_only.mainpres_subs_ewcnone_rcolmain_adm1_1hot found\n",
      "topic_only.mainpres_subs_ewcnone_rcolmain_adm1_1hot found\n",
      "no_unobs.mainold_subs_ewcnone_rcolmain_adm1_1hot found\n",
      "no_unobs.mainpres_subs_ewcnone_rcolmain_adm1_1hot found\n",
      "topic_only_oracle.mainold_subs_ewcnone_rcolmain_adm1_1hot found\n",
      "topic_only_oracle.mainpres_subs_ewcnone_rcolmain_adm1_1hot found\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "res_dir = Path(\"/scratch/fitzgeraldj/data/caus_inf_data/results\")\n",
    "exps = 5\n",
    "# embed = \"user\"\n",
    "sub_choices = [\"old_subs\", \"pres_subs\"]\n",
    "regions = [\"adm1\", \"ctry\"]  # or \"ctry\" for dsbmm_dpf models\n",
    "base_models = [\n",
    "    \"unadjusted.main\",\n",
    "    \"network_pref_only.main\",\n",
    "    \"topic_only.main\",\n",
    "    \"no_unobs.main\",\n",
    "    \"topic_only_oracle.main\",\n",
    "    \"dsbmm_dpf.z-only\",\n",
    "    \"dsbmm_dpf.z-theta-joint\",\n",
    "    \"dsbmm_dpf.z-theta-joint-ndc\",\n",
    "]\n",
    "models = [\n",
    "    m + f\"{sub_choice}_ewcnone_rcolmain_{region}_1hot\"\n",
    "    for m in base_models\n",
    "    for sub_choice in sub_choices\n",
    "    for region in regions\n",
    "]\n",
    "\n",
    "conf_types = [\"homophily\", \"exog\", \"both\"]\n",
    "confounding_strengths = [(50, 10), (50, 50), (50, 100)]\n",
    "exp_results = {}\n",
    "found = set()\n",
    "\n",
    "for i in range(1, exps + 1):\n",
    "    for model in models:\n",
    "        for (cov1conf, cov2conf) in confounding_strengths:\n",
    "            for ct in conf_types:\n",
    "                try:\n",
    "                    base_file_name = (\n",
    "                        \"conf=\"\n",
    "                        + str((cov1conf, cov2conf))\n",
    "                        + \";conf_type=\"\n",
    "                        + ct\n",
    "                        + \".npz\"\n",
    "                    )\n",
    "                    result_file = (\n",
    "                        (res_dir / str(i)) / (model + \"_model_fitted_params\")\n",
    "                    ) / base_file_name\n",
    "                    res = np.load(result_file)\n",
    "                    params = res[\"fitted\"]\n",
    "                    truth = res[\"true\"]\n",
    "\n",
    "                    if (ct, (cov1conf, cov2conf)) in exp_results:\n",
    "                        if model in exp_results[(ct, (cov1conf, cov2conf))]:\n",
    "                            exp_results[(ct, (cov1conf, cov2conf))][model].append(\n",
    "                                (params, truth)\n",
    "                            )\n",
    "                        else:\n",
    "                            exp_results[(ct, (cov1conf, cov2conf))][model] = [\n",
    "                                (params, truth)\n",
    "                            ]\n",
    "                    else:\n",
    "                        exp_results[(ct, (cov1conf, cov2conf))] = {\n",
    "                            model: [(params, truth)]\n",
    "                        }\n",
    "                    if model not in found:\n",
    "                        print(model, \"found\")\n",
    "                        found |= set([model])\n",
    "                except:\n",
    "                    # print(result_file, \" not found\")\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounding_type = \"exog\"\n",
    "models = list(exp_results[(confounding_type, confounding_strengths[1])].keys())\n",
    "regime1 = {\n",
    "    \"Low\": (confounding_type, confounding_strengths[0]),\n",
    "    \"Med.\": (confounding_type, confounding_strengths[1]),\n",
    "    \"High\": (confounding_type, confounding_strengths[2]),\n",
    "}\n",
    "\n",
    "df1, alt_df1 = print_table(exp_results, regime1, models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounding_type = \"homophily\"\n",
    "models = list(exp_results[(confounding_type, confounding_strengths[0])].keys())\n",
    "regime1 = {\n",
    "    \"Low\": (confounding_type, confounding_strengths[0]),\n",
    "    \"Med.\": (confounding_type, confounding_strengths[1]),\n",
    "    \"High\": (confounding_type, confounding_strengths[2]),\n",
    "}\n",
    "\n",
    "df2, alt_df2 = print_table(exp_results, regime1, models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounding_type = \"both\"\n",
    "models = list(exp_results[(confounding_type, confounding_strengths[0])].keys())\n",
    "regime1 = {\n",
    "    \"Low\": (confounding_type, confounding_strengths[0]),\n",
    "    \"Med.\": (confounding_type, confounding_strengths[1]),\n",
    "    \"High\": (confounding_type, confounding_strengths[2]),\n",
    "}\n",
    "\n",
    "df3, alt_df3 = print_table(exp_results, regime1, models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_results = pd.concat([df1, df2, df3], axis=1, keys=[\"Exog.\", \"Homophily\", \"Both\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[all_results == all_results.min(axis=0)] = (\n",
    "    \"\\textbf{\" + all_results[all_results == all_results.min(axis=0)] + \"}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.index = all_results.index.str.wrap(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.to_latex(\"./results/semi-synth.tex\", escape=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_all_results = pd.concat(\n",
    "    [alt_df1, alt_df2, alt_df3], axis=1, keys=[\"Exog.\", \"Homophily\", \"Both\"]\n",
    ")\n",
    "alt_all_results.index=alt_all_results.index.str.wrap(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_all_results[alt_all_results == alt_all_results.min(axis=0)] = (\n",
    "    \"\\textbf{\" + alt_all_results[alt_all_results == alt_all_results.min(axis=0)] + \"}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Exog.</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Homophily</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Both</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Low</th>\n",
       "      <th>Med.</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Med.</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Med.</th>\n",
       "      <th>High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ours-no-meta-\\nold-A</th>\n",
       "      <td>0.8$\\pm$2.23</td>\n",
       "      <td>1.22$\\pm$3.69</td>\n",
       "      <td>1.06$\\pm$2.37</td>\n",
       "      <td>4.07$\\pm$8.69</td>\n",
       "      <td>5.59$\\pm$12.8</td>\n",
       "      <td>4.29$\\pm$8.22</td>\n",
       "      <td>6.18$\\pm$12.27</td>\n",
       "      <td>3.61$\\pm$7.82</td>\n",
       "      <td>3.89$\\pm$8.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ours-no-meta-\\npres-A</th>\n",
       "      <td>0.8$\\pm$2.23</td>\n",
       "      <td>1.21$\\pm$3.69</td>\n",
       "      <td>1.06$\\pm$2.37</td>\n",
       "      <td>4.18$\\pm$9.03</td>\n",
       "      <td>5.58$\\pm$12.82</td>\n",
       "      <td>4.27$\\pm$8.21</td>\n",
       "      <td>6.19$\\pm$12.28</td>\n",
       "      <td>3.59$\\pm$7.8</td>\n",
       "      <td>3.87$\\pm$8.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ours-old-A</th>\n",
       "      <td>0.8$\\pm$2.22</td>\n",
       "      <td>1.23$\\pm$3.68</td>\n",
       "      <td>1.15$\\pm$2.39</td>\n",
       "      <td>5.86$\\pm$11.87</td>\n",
       "      <td>4.45$\\pm$8.62</td>\n",
       "      <td>4.3$\\pm$8.28</td>\n",
       "      <td>6.22$\\pm$12.31</td>\n",
       "      <td>4.81$\\pm$9.17</td>\n",
       "      <td>4.94$\\pm$9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ours-old-C</th>\n",
       "      <td>0.81$\\pm$2.24</td>\n",
       "      <td>1.24$\\pm$3.72</td>\n",
       "      <td>1.15$\\pm$2.41</td>\n",
       "      <td>6.34$\\pm$12.21</td>\n",
       "      <td>4.59$\\pm$8.64</td>\n",
       "      <td>4.43$\\pm$8.32</td>\n",
       "      <td>6.37$\\pm$12.28</td>\n",
       "      <td>4.94$\\pm$9.16</td>\n",
       "      <td>5.09$\\pm$9.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ours-pres-A</th>\n",
       "      <td>0.92$\\pm$2.28</td>\n",
       "      <td>1.25$\\pm$3.72</td>\n",
       "      <td>1.16$\\pm$2.42</td>\n",
       "      <td>8.51$\\pm$21.57</td>\n",
       "      <td>4.92$\\pm$8.89</td>\n",
       "      <td>4.43$\\pm$8.67</td>\n",
       "      <td>6.37$\\pm$12.32</td>\n",
       "      <td>5.11$\\pm$9.46</td>\n",
       "      <td>5.24$\\pm$9.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ours-pres-C</th>\n",
       "      <td>0.89$\\pm$2.27</td>\n",
       "      <td>1.23$\\pm$3.65</td>\n",
       "      <td>1.16$\\pm$2.4</td>\n",
       "      <td>7.71$\\pm$17.74</td>\n",
       "      <td>5.29$\\pm$11.0</td>\n",
       "      <td>4.83$\\pm$9.72</td>\n",
       "      <td>6.42$\\pm$12.43</td>\n",
       "      <td>5.19$\\pm$9.73</td>\n",
       "      <td>5.48$\\pm$10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ours-no-meta-\\nold-C</th>\n",
       "      <td>0.43$\\pm$1.5</td>\n",
       "      <td>0.5$\\pm$1.41</td>\n",
       "      <td>0.64$\\pm$1.67</td>\n",
       "      <td>3.97$\\pm$10.17</td>\n",
       "      <td>2.34$\\pm$6.11</td>\n",
       "      <td>1.97$\\pm$4.34</td>\n",
       "      <td>4.16$\\pm$10.8</td>\n",
       "      <td>2.42$\\pm$5.86</td>\n",
       "      <td>2.55$\\pm$5.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ours-no-meta-\\npres-C</th>\n",
       "      <td>0.41$\\pm$1.5</td>\n",
       "      <td>0.49$\\pm$1.41</td>\n",
       "      <td>0.64$\\pm$1.67</td>\n",
       "      <td>1.96$\\pm$4.37</td>\n",
       "      <td>3.11$\\pm$8.12</td>\n",
       "      <td>1.95$\\pm$4.32</td>\n",
       "      <td>4.13$\\pm$10.77</td>\n",
       "      <td>2.4$\\pm$5.83</td>\n",
       "      <td>2.52$\\pm$5.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ours-NDC-pres-A</th>\n",
       "      <td>0.22$\\pm$0.92</td>\n",
       "      <td>0.22$\\pm$0.97</td>\n",
       "      <td>0.11$\\pm$0.37</td>\n",
       "      <td>10.72$\\pm$32.17</td>\n",
       "      <td>3.99$\\pm$9.56</td>\n",
       "      <td>0.47$\\pm$1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unadjusted-\\nold-A</th>\n",
       "      <td>0.07$\\pm$0.22</td>\n",
       "      <td>0.11$\\pm$0.34</td>\n",
       "      <td>0.1$\\pm$0.33</td>\n",
       "      <td>1.43$\\pm$5.4</td>\n",
       "      <td>1.44$\\pm$5.46</td>\n",
       "      <td>1.18$\\pm$4.13</td>\n",
       "      <td>2.64$\\pm$11.58</td>\n",
       "      <td>1.71$\\pm$6.77</td>\n",
       "      <td>1.42$\\pm$5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unadjusted-\\npres-A</th>\n",
       "      <td>0.07$\\pm$0.22</td>\n",
       "      <td>0.11$\\pm$0.34</td>\n",
       "      <td>0.1$\\pm$0.33</td>\n",
       "      <td>1.58$\\pm$6.23</td>\n",
       "      <td>1.44$\\pm$5.46</td>\n",
       "      <td>1.18$\\pm$4.13</td>\n",
       "      <td>2.64$\\pm$11.58</td>\n",
       "      <td>1.71$\\pm$6.77</td>\n",
       "      <td>1.42$\\pm$5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net.-only-\\npres-A</th>\n",
       "      <td>0.23$\\pm$0.99</td>\n",
       "      <td>0.13$\\pm$0.44</td>\n",
       "      <td>0.14$\\pm$0.45</td>\n",
       "      <td>2.22$\\pm$11.17</td>\n",
       "      <td>0.78$\\pm$2.44</td>\n",
       "      <td>1.97$\\pm$8.79</td>\n",
       "      <td>4.49$\\pm$16.29</td>\n",
       "      <td>1.63$\\pm$7.18</td>\n",
       "      <td>0.81$\\pm$2.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic-only-\\npres-A</th>\n",
       "      <td>0.04$\\pm$0.12</td>\n",
       "      <td>0.07$\\pm$0.21</td>\n",
       "      <td>0.06$\\pm$0.2</td>\n",
       "      <td>\\textbf{1.07$\\pm$5.53}</td>\n",
       "      <td>0.8$\\pm$3.69</td>\n",
       "      <td>0.44$\\pm$1.58</td>\n",
       "      <td>1.17$\\pm$6.08</td>\n",
       "      <td>1.08$\\pm$5.18</td>\n",
       "      <td>0.65$\\pm$2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oracle-old-A</th>\n",
       "      <td>0.03$\\pm$0.1</td>\n",
       "      <td>0.03$\\pm$0.11</td>\n",
       "      <td>0.03$\\pm$0.12</td>\n",
       "      <td>2.03$\\pm$10.8</td>\n",
       "      <td>1.26$\\pm$6.68</td>\n",
       "      <td>0.63$\\pm$3.35</td>\n",
       "      <td>2.62$\\pm$13.92</td>\n",
       "      <td>1.27$\\pm$6.75</td>\n",
       "      <td>0.87$\\pm$4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oracle-pres-A</th>\n",
       "      <td>0.03$\\pm$0.12</td>\n",
       "      <td>0.04$\\pm$0.13</td>\n",
       "      <td>0.04$\\pm$0.14</td>\n",
       "      <td>3.21$\\pm$16.96</td>\n",
       "      <td>1.31$\\pm$6.59</td>\n",
       "      <td>0.74$\\pm$3.31</td>\n",
       "      <td>2.68$\\pm$14.09</td>\n",
       "      <td>1.31$\\pm$6.6</td>\n",
       "      <td>0.94$\\pm$4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic-oracle-\\nold-A</th>\n",
       "      <td>0.01$\\pm$0.03</td>\n",
       "      <td>0.01$\\pm$0.04</td>\n",
       "      <td>0.01$\\pm$0.04</td>\n",
       "      <td>1.86$\\pm$9.26</td>\n",
       "      <td>1.31$\\pm$6.08</td>\n",
       "      <td>0.9$\\pm$3.69</td>\n",
       "      <td>2.49$\\pm$12.63</td>\n",
       "      <td>1.75$\\pm$8.41</td>\n",
       "      <td>1.08$\\pm$4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic-oracle-\\npres-A</th>\n",
       "      <td>0.03$\\pm$0.08</td>\n",
       "      <td>0.03$\\pm$0.1</td>\n",
       "      <td>0.03$\\pm$0.11</td>\n",
       "      <td>1.46$\\pm$7.09</td>\n",
       "      <td>1.31$\\pm$6.08</td>\n",
       "      <td>0.9$\\pm$3.7</td>\n",
       "      <td>2.52$\\pm$12.76</td>\n",
       "      <td>1.78$\\pm$8.57</td>\n",
       "      <td>1.08$\\pm$4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ours-NDC-old-A</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.02$\\pm$37.04</td>\n",
       "      <td>\\textbf{0.0$\\pm$0.0}</td>\n",
       "      <td>\\textbf{0.0$\\pm$0.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Exog.                                \\\n",
       "                                 Low           Med.           High   \n",
       "Ours-no-meta-\\nold-A    0.8$\\pm$2.23  1.22$\\pm$3.69  1.06$\\pm$2.37   \n",
       "Ours-no-meta-\\npres-A   0.8$\\pm$2.23  1.21$\\pm$3.69  1.06$\\pm$2.37   \n",
       "Ours-old-A              0.8$\\pm$2.22  1.23$\\pm$3.68  1.15$\\pm$2.39   \n",
       "Ours-old-C             0.81$\\pm$2.24  1.24$\\pm$3.72  1.15$\\pm$2.41   \n",
       "Ours-pres-A            0.92$\\pm$2.28  1.25$\\pm$3.72  1.16$\\pm$2.42   \n",
       "Ours-pres-C            0.89$\\pm$2.27  1.23$\\pm$3.65   1.16$\\pm$2.4   \n",
       "Ours-no-meta-\\nold-C    0.43$\\pm$1.5   0.5$\\pm$1.41  0.64$\\pm$1.67   \n",
       "Ours-no-meta-\\npres-C   0.41$\\pm$1.5  0.49$\\pm$1.41  0.64$\\pm$1.67   \n",
       "Ours-NDC-pres-A        0.22$\\pm$0.92  0.22$\\pm$0.97  0.11$\\pm$0.37   \n",
       "Unadjusted-\\nold-A     0.07$\\pm$0.22  0.11$\\pm$0.34   0.1$\\pm$0.33   \n",
       "Unadjusted-\\npres-A    0.07$\\pm$0.22  0.11$\\pm$0.34   0.1$\\pm$0.33   \n",
       "Net.-only-\\npres-A     0.23$\\pm$0.99  0.13$\\pm$0.44  0.14$\\pm$0.45   \n",
       "Topic-only-\\npres-A    0.04$\\pm$0.12  0.07$\\pm$0.21   0.06$\\pm$0.2   \n",
       "Oracle-old-A            0.03$\\pm$0.1  0.03$\\pm$0.11  0.03$\\pm$0.12   \n",
       "Oracle-pres-A          0.03$\\pm$0.12  0.04$\\pm$0.13  0.04$\\pm$0.14   \n",
       "Topic-oracle-\\nold-A   0.01$\\pm$0.03  0.01$\\pm$0.04  0.01$\\pm$0.04   \n",
       "Topic-oracle-\\npres-A  0.03$\\pm$0.08   0.03$\\pm$0.1  0.03$\\pm$0.11   \n",
       "Ours-NDC-old-A                   NaN            NaN            NaN   \n",
       "\n",
       "                                    Homophily                        \\\n",
       "                                          Low                  Med.   \n",
       "Ours-no-meta-\\nold-A            4.07$\\pm$8.69         5.59$\\pm$12.8   \n",
       "Ours-no-meta-\\npres-A           4.18$\\pm$9.03        5.58$\\pm$12.82   \n",
       "Ours-old-A                     5.86$\\pm$11.87         4.45$\\pm$8.62   \n",
       "Ours-old-C                     6.34$\\pm$12.21         4.59$\\pm$8.64   \n",
       "Ours-pres-A                    8.51$\\pm$21.57         4.92$\\pm$8.89   \n",
       "Ours-pres-C                    7.71$\\pm$17.74         5.29$\\pm$11.0   \n",
       "Ours-no-meta-\\nold-C           3.97$\\pm$10.17         2.34$\\pm$6.11   \n",
       "Ours-no-meta-\\npres-C           1.96$\\pm$4.37         3.11$\\pm$8.12   \n",
       "Ours-NDC-pres-A               10.72$\\pm$32.17         3.99$\\pm$9.56   \n",
       "Unadjusted-\\nold-A               1.43$\\pm$5.4         1.44$\\pm$5.46   \n",
       "Unadjusted-\\npres-A             1.58$\\pm$6.23         1.44$\\pm$5.46   \n",
       "Net.-only-\\npres-A             2.22$\\pm$11.17         0.78$\\pm$2.44   \n",
       "Topic-only-\\npres-A    \\textbf{1.07$\\pm$5.53}          0.8$\\pm$3.69   \n",
       "Oracle-old-A                    2.03$\\pm$10.8         1.26$\\pm$6.68   \n",
       "Oracle-pres-A                  3.21$\\pm$16.96         1.31$\\pm$6.59   \n",
       "Topic-oracle-\\nold-A            1.86$\\pm$9.26         1.31$\\pm$6.08   \n",
       "Topic-oracle-\\npres-A           1.46$\\pm$7.09         1.31$\\pm$6.08   \n",
       "Ours-NDC-old-A                 7.02$\\pm$37.04  \\textbf{0.0$\\pm$0.0}   \n",
       "\n",
       "                                                       Both                 \\\n",
       "                                       High             Low           Med.   \n",
       "Ours-no-meta-\\nold-A          4.29$\\pm$8.22  6.18$\\pm$12.27  3.61$\\pm$7.82   \n",
       "Ours-no-meta-\\npres-A         4.27$\\pm$8.21  6.19$\\pm$12.28   3.59$\\pm$7.8   \n",
       "Ours-old-A                     4.3$\\pm$8.28  6.22$\\pm$12.31  4.81$\\pm$9.17   \n",
       "Ours-old-C                    4.43$\\pm$8.32  6.37$\\pm$12.28  4.94$\\pm$9.16   \n",
       "Ours-pres-A                   4.43$\\pm$8.67  6.37$\\pm$12.32  5.11$\\pm$9.46   \n",
       "Ours-pres-C                   4.83$\\pm$9.72  6.42$\\pm$12.43  5.19$\\pm$9.73   \n",
       "Ours-no-meta-\\nold-C          1.97$\\pm$4.34   4.16$\\pm$10.8  2.42$\\pm$5.86   \n",
       "Ours-no-meta-\\npres-C         1.95$\\pm$4.32  4.13$\\pm$10.77   2.4$\\pm$5.83   \n",
       "Ours-NDC-pres-A                0.47$\\pm$1.6             NaN            NaN   \n",
       "Unadjusted-\\nold-A            1.18$\\pm$4.13  2.64$\\pm$11.58  1.71$\\pm$6.77   \n",
       "Unadjusted-\\npres-A           1.18$\\pm$4.13  2.64$\\pm$11.58  1.71$\\pm$6.77   \n",
       "Net.-only-\\npres-A            1.97$\\pm$8.79  4.49$\\pm$16.29  1.63$\\pm$7.18   \n",
       "Topic-only-\\npres-A           0.44$\\pm$1.58   1.17$\\pm$6.08  1.08$\\pm$5.18   \n",
       "Oracle-old-A                  0.63$\\pm$3.35  2.62$\\pm$13.92  1.27$\\pm$6.75   \n",
       "Oracle-pres-A                 0.74$\\pm$3.31  2.68$\\pm$14.09   1.31$\\pm$6.6   \n",
       "Topic-oracle-\\nold-A           0.9$\\pm$3.69  2.49$\\pm$12.63  1.75$\\pm$8.41   \n",
       "Topic-oracle-\\npres-A           0.9$\\pm$3.7  2.52$\\pm$12.76  1.78$\\pm$8.57   \n",
       "Ours-NDC-old-A         \\textbf{0.0$\\pm$0.0}             NaN            NaN   \n",
       "\n",
       "                                       \n",
       "                                 High  \n",
       "Ours-no-meta-\\nold-A    3.89$\\pm$8.22  \n",
       "Ours-no-meta-\\npres-A   3.87$\\pm$8.21  \n",
       "Ours-old-A              4.94$\\pm$9.35  \n",
       "Ours-old-C              5.09$\\pm$9.39  \n",
       "Ours-pres-A             5.24$\\pm$9.75  \n",
       "Ours-pres-C            5.48$\\pm$10.66  \n",
       "Ours-no-meta-\\nold-C    2.55$\\pm$5.97  \n",
       "Ours-no-meta-\\npres-C   2.52$\\pm$5.93  \n",
       "Ours-NDC-pres-A                   NaN  \n",
       "Unadjusted-\\nold-A       1.42$\\pm$5.3  \n",
       "Unadjusted-\\npres-A      1.42$\\pm$5.3  \n",
       "Net.-only-\\npres-A      0.81$\\pm$2.56  \n",
       "Topic-only-\\npres-A      0.65$\\pm$2.7  \n",
       "Oracle-old-A             0.87$\\pm$4.6  \n",
       "Oracle-pres-A           0.94$\\pm$4.41  \n",
       "Topic-oracle-\\nold-A    1.08$\\pm$4.68  \n",
       "Topic-oracle-\\npres-A   1.08$\\pm$4.67  \n",
       "Ours-NDC-old-A                    NaN  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt_all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_all_results.to_latex(\"./results/alt-semi-synth.tex\", escape=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# load up PPC results\n",
    "with open(res_dir / \"dsbmm_ppc_results.pkl\", \"rb\") as f:\n",
    "    dsbmm_ppc_results = pickle.load(f)\n",
    "with open(res_dir / \"dpf_ppc_results.pkl\", \"rb\") as f:\n",
    "    dpf_ppc_results = pickle.load(f)\n",
    "with open(res_dir / \"dpf_auc_results.pkl\", \"rb\") as f:\n",
    "    dpf_auc_results = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in shape (n_exps,n_Q_tested)\n",
    "# where each experiment is a subsample of the data using a different seed\n",
    "# each value is then n_pos / n_repls, where n_pos counts the number of\n",
    "# replicates in which the likelihood of observing the replicated data\n",
    "# was greater than observing the held-out data, after fitting on the\n",
    "# remaining data\n",
    "dpf_ppc_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.50910372, 0.5927523 , 0.72340592, 0.83475554],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpf_auc_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsbmm_ppc_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.stack([dsbmm_ppc_results.mean(axis=0), dpf_ppc_results.mean(axis=0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc_df = pd.DataFrame(tmp.T, columns=[\"$A$\", \"$Y$\"])\n",
    "ppc_df[\"$Q$\"] = [4, 9, 16]\n",
    "ppc_df[\"$K$\"] = [3, 5, 8]\n",
    "ppc_df[[\"$K$\", \"$Y$\"]].to_latex(\"./results/topic-synth-ppcs.tex\", escape=False)\n",
    "ppc_df[[\"$Q$\", \"$A$\"]].to_latex(\"./results/auth-synth-ppcs.tex\", escape=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$K$</th>\n",
       "      <th>$Y$</th>\n",
       "      <th>$Q$</th>\n",
       "      <th>$A$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   $K$   $Y$  $Q$   $A$\n",
       "0    3  0.05    4  0.05\n",
       "1    5  0.05    9  0.05\n",
       "2    8  0.05   16  0.05"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppc_df[[\"$K$\", \"$Y$\", \"$Q$\", \"$A$\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pif_dsbmm_dpf.citation.predictive_check import calculate_ppc_dsbmm, mask_topics\n",
    "\n",
    "exp_idx = 0\n",
    "Q = 4\n",
    "dsbmm_datadir = res_dir.parent / \"dsbmm_data\"\n",
    "with open(dsbmm_datadir / f\"dsbmmppc_runsim_model_{exp_idx}_Q{Q}_subs.pkl\", \"rb\") as f:\n",
    "    node_probs, Z_trans, block_probs = pickle.load(f)\n",
    "with open(res_dir.parent / f\"sim_model_{exp_idx}.pkl\", \"rb\") as f:\n",
    "    sim_model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving semi-synth data to /scratch/fitzgeraldj/data/caus_inf_data/sim_model_0.pkl\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(exp_idx)\n",
    "Y = sim_model.make_multi_covariate_simulation(\n",
    "    noise=10.0, confounding_strength=50.0, confounding_to_use=\"both\"\n",
    ")\n",
    "A = sim_model.A\n",
    "N = Y[0].shape[0]\n",
    "M = Y[0].shape[1]\n",
    "T = len(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_friends = [mask_topics(N, N) for _ in range(T - 1)]\n",
    "aus = np.arange(N, dtype=int)\n",
    "masked_friends = [(aus.copy(), mf) for mf in masked_friends]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "np.random.seed(int(time.time()) % 2**32)\n",
    "A_ll_heldout, A_ll_repl, e_rates = calculate_ppc_dsbmm(masked_friends,A,node_probs,block_probs,ret_rates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_degs = A[-1].sum(axis=0)\n",
    "out_degs = A[-1].sum(axis=1)\n",
    "# in_degs[in_degs == 0] = 1.0\n",
    "# out_degs[out_degs == 0] = 1.0\n",
    "pos_nodes = (in_degs > 0) & (out_degs > 0)\n",
    "e_rates = np.einsum(\n",
    "    \"iq,qr,jr->ij\",\n",
    "    out_degs[pos_nodes, np.newaxis] * node_probs[pos_nodes, -1, :],\n",
    "    block_probs[..., -1],\n",
    "    in_degs[pos_nodes, np.newaxis] * node_probs[pos_nodes, -1, :],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled w no out citations: 0\n",
      "Sampled w no in citations: 0\n"
     ]
    }
   ],
   "source": [
    "good_samp_idxs = np.isin(masked_friends[-1][1], pos_nodes)\n",
    "tmp_j = masked_friends[-1][1][good_samp_idxs]\n",
    "tmp_i = masked_friends[-1][0][good_samp_idxs]\n",
    "print(f\"Sampled w no out citations: {(A[-1][tmp_j,:].sum(axis=1) == 0).sum()}\")\n",
    "print(f\"Sampled w no in citations: {(A[-1][:,tmp_j].sum(axis=0) == 0).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ah this was using incorrectly calculated block probs -- reupdate directly instead\n",
    "tp_marg = np.einsum(\n",
    "    \"iq,ijqr,jr->ijqr\",\n",
    "    node_probs[:, -1, :],\n",
    "    poisson.pmf(\n",
    "        A[-1].toarray()[..., np.newaxis, np.newaxis],\n",
    "        out_degs[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "        * in_degs[np.newaxis, :, np.newaxis, np.newaxis]\n",
    "        * block_probs[..., -1][np.newaxis, np.newaxis],\n",
    "    ),\n",
    "    node_probs[:, -1, :],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3964767/1852495868.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  tp_marg /= tp_marg.sum(axis=(-2,-1),keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "tp_marg /= tp_marg.sum(axis=(-2,-1),keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_block_probs_num = np.nansum(\n",
    "    tp_marg[np.ix_(pos_nodes,pos_nodes)]*(A[-1].toarray()[np.ix_(pos_nodes,pos_nodes)][...,np.newaxis,np.newaxis]),axis=(0,1)\n",
    ")\n",
    "eff_block_probs_denom = np.einsum(\n",
    "    \"iq,jr->qr\",\n",
    "    out_degs[pos_nodes, np.newaxis] * node_probs[pos_nodes, -1, :],\n",
    "    in_degs[pos_nodes, np.newaxis] * node_probs[pos_nodes, -1, :],\n",
    ")\n",
    "eff_block_probs = np.divide(\n",
    "    eff_block_probs_num,\n",
    "    eff_block_probs_denom,\n",
    "    where=eff_block_probs_denom > 0,\n",
    "    out=np.zeros_like(eff_block_probs_denom),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04923098262431963"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[-1].nnz / (A[-1].shape[0] ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_e_rates = np.einsum(\n",
    "    \"iq,qr,jr->ij\",\n",
    "    out_degs[pos_nodes, np.newaxis] * node_probs[pos_nodes, -1, :],\n",
    "    eff_block_probs,\n",
    "    in_degs[pos_nodes, np.newaxis] * node_probs[pos_nodes, -1, :],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import poisson\n",
    "\n",
    "heldout = A[-1][masked_friends[-1][0],masked_friends[-1][1]]\n",
    "ppc = 0.0\n",
    "repls = 100\n",
    "rev_idx = np.zeros(N,dtype=int)\n",
    "rev_idx[pos_nodes] = np.arange(pos_nodes.sum(),dtype=int)\n",
    "sub_mask_i = masked_friends[-1][0]\n",
    "sub_mask_j = masked_friends[-1][1]\n",
    "joint_mask = np.isin(sub_mask_i,np.flatnonzero(pos_nodes)) & np.isin(sub_mask_j,np.flatnonzero(pos_nodes))\n",
    "sub_mask_i = sub_mask_i[joint_mask]\n",
    "sub_mask_j = sub_mask_j[joint_mask]\n",
    "\n",
    "subset_rates = eff_e_rates[rev_idx[sub_mask_i],rev_idx[sub_mask_j]]\n",
    "for _ in range(repls):\n",
    "    samps = poisson.rvs(subset_rates)\n",
    "    ho_ll = poisson.logpmf(heldout[joint_mask],subset_rates).sum()\n",
    "    rep_ll = poisson.logpmf(samps,subset_rates).sum()\n",
    "    if rep_ll > ho_ll:\n",
    "        ppc += 1.0\n",
    "print(ppc/repls)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recalc PPCs for incorrect block prob samples \n",
    "- NB will only work at all for smaller numbers of groups, where dividing by n_descs is less of a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving semi-synth data to /scratch/fitzgeraldj/data/caus_inf_data/sim_model_0.pkl\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import poisson\n",
    "import time\n",
    "from pif_dsbmm_dpf.citation.predictive_check import calculate_ppc_dsbmm, mask_topics\n",
    "\n",
    "exp_idx = 0\n",
    "dsbmm_datadir = res_dir.parent / \"dsbmm_data\"\n",
    "with open(res_dir.parent / f\"sim_model_{exp_idx}.pkl\", \"rb\") as f:\n",
    "    sim_model = pickle.load(f)\n",
    "np.random.seed(exp_idx)\n",
    "Y = sim_model.make_multi_covariate_simulation(\n",
    "    noise=10.0, confounding_strength=50.0, confounding_to_use=\"both\"\n",
    ")\n",
    "A = sim_model.A\n",
    "N = Y[0].shape[0]\n",
    "M = Y[0].shape[1]\n",
    "T = len(Y)\n",
    "masked_friends = [mask_topics(N, N) for _ in range(T - 1)]\n",
    "aus = np.arange(N, dtype=int)\n",
    "masked_friends = [(aus.copy(), mf) for mf in masked_friends]\n",
    "heldout = A[-1][masked_friends[-1][0],masked_friends[-1][1]]\n",
    "in_degs = A[-1].sum(axis=0)\n",
    "out_degs = A[-1].sum(axis=1)\n",
    "\n",
    "pos_nodes = (in_degs > 0) & (out_degs > 0)\n",
    "Qs = [4,9,16]\n",
    "ppc_scores = np.zeros(len(Qs))\n",
    "for q_idx,Q in enumerate(Qs):\n",
    "    with open(dsbmm_datadir / f\"dsbmmppc_runsim_model_{exp_idx}_Q{Q}_subs.pkl\", \"rb\") as f:\n",
    "        node_probs, Z_trans, block_probs = pickle.load(f)\n",
    "\n",
    "    np.random.seed(int(time.time()) % 2**32)\n",
    "    \n",
    "    \n",
    "    \n",
    "    tp_marg = np.einsum(\n",
    "        \"iq,ijqr,jr->ijqr\",\n",
    "        node_probs[:, -1, :],\n",
    "        poisson.pmf(\n",
    "            A[-1].toarray()[..., np.newaxis, np.newaxis],\n",
    "            out_degs[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "            * in_degs[np.newaxis, :, np.newaxis, np.newaxis]\n",
    "            * block_probs[..., -1][np.newaxis, np.newaxis],\n",
    "        ),\n",
    "        node_probs[:, -1, :],\n",
    "    )\n",
    "    tp_marg_sums = np.nansum(tp_marg,axis=(-2,-1),keepdims=True)\n",
    "    tp_marg = np.divide(tp_marg,tp_marg_sums,where=tp_marg_sums>0,out=np.zeros_like(tp_marg))\n",
    "    eff_block_probs_num = np.nansum(\n",
    "        tp_marg[np.ix_(pos_nodes,pos_nodes)]*(A[-1].toarray()[np.ix_(pos_nodes,pos_nodes)][...,np.newaxis,np.newaxis]),axis=(0,1)\n",
    "    )\n",
    "    eff_block_probs_denom = np.einsum(\n",
    "        \"iq,jr->qr\",\n",
    "        out_degs[pos_nodes, np.newaxis] * node_probs[pos_nodes, -1, :],\n",
    "        in_degs[pos_nodes, np.newaxis] * node_probs[pos_nodes, -1, :],\n",
    "    )\n",
    "    eff_block_probs = np.divide(\n",
    "        eff_block_probs_num,\n",
    "        eff_block_probs_denom,\n",
    "        where=eff_block_probs_denom > 0,\n",
    "        out=np.zeros_like(eff_block_probs_denom),\n",
    "    )\n",
    "\n",
    "    eff_e_rates = np.einsum(\n",
    "        \"iq,qr,jr->ij\",\n",
    "        out_degs[pos_nodes, np.newaxis] * node_probs[pos_nodes, -1, :],\n",
    "        eff_block_probs,\n",
    "        in_degs[pos_nodes, np.newaxis] * node_probs[pos_nodes, -1, :],\n",
    "    )\n",
    "    ppc = 0.0\n",
    "    repls = 100\n",
    "    rev_idx = np.zeros(N,dtype=int)\n",
    "    rev_idx[pos_nodes] = np.arange(pos_nodes.sum(),dtype=int)\n",
    "    sub_mask_i = masked_friends[-1][0]\n",
    "    sub_mask_j = masked_friends[-1][1]\n",
    "    joint_mask = np.isin(sub_mask_i,np.flatnonzero(pos_nodes)) & np.isin(sub_mask_j,np.flatnonzero(pos_nodes))\n",
    "    sub_mask_i = sub_mask_i[joint_mask]\n",
    "    sub_mask_j = sub_mask_j[joint_mask]\n",
    "\n",
    "    subset_rates = eff_e_rates[rev_idx[sub_mask_i],rev_idx[sub_mask_j]]\n",
    "    for _ in range(repls):\n",
    "        samps = poisson.rvs(subset_rates)\n",
    "        ho_ll = poisson.logpmf(heldout[joint_mask],subset_rates).sum()\n",
    "        rep_ll = poisson.logpmf(samps,subset_rates).sum()\n",
    "        if rep_ll > ho_ll:\n",
    "            ppc += 1.0\n",
    "    ppc_scores[q_idx] = ppc/repls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26, 1.  , 1.  ])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dsbmm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7e9ac61dd33495e99df2de3821e149f85d8202ddba18b6ff083e03353ac2ec5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
